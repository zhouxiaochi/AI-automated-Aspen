#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
CSVåˆå¹¶å·¥å…·ï¼šå°†æ‰€æœ‰è§£æåçš„table CSVæ–‡ä»¶åˆå¹¶ä¸ºæœ€ç»ˆçš„åŒ–åˆç‰©æ•°æ®åº“
"""

from pathlib import Path
import csv
import re

def merge_csv_files(input_dir, output_file):
    """åˆå¹¶æ‰€æœ‰CSVæ–‡ä»¶"""
    
    print("ğŸ”§ CSVæ–‡ä»¶åˆå¹¶å·¥å…·")
    print("=" * 50)
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = sorted(input_dir.glob("table_*.csv"))
    
    if not csv_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶åœ¨ {input_dir}")
        return
    
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“„ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print()
    
    # ç»Ÿè®¡æ•°æ®
    total_compounds = 0
    processed_files = 0
    failed_files = []
    all_compounds = []
    seen_pairs = set()  # å»é‡ç”¨
    
    # é€ä¸ªå¤„ç†CSVæ–‡ä»¶
    for csv_file in csv_files:
        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                file_compounds = 0
                
                for row in reader:
                    databank = row.get('databank', '').strip()
                    alias = row.get('alias_or_code', '').strip().upper()
                    name = row.get('registered_name', '').strip().upper()
                    
                    # åŸºæœ¬éªŒè¯
                    if alias and name and databank:
                        # å»é‡ï¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„alias-nameå¯¹
                        pair_key = (alias, name)
                        if pair_key not in seen_pairs:
                            seen_pairs.add(pair_key)
                            all_compounds.append({
                                'databank': databank,
                                'alias_or_code': alias,
                                'registered_name': name,
                                'source_table': csv_file.stem
                            })
                            file_compounds += 1
                
                total_compounds += file_compounds
                processed_files += 1
                print(f"âœ… {csv_file.name}: {file_compounds:3d} åŒ–åˆç‰©")
                
        except Exception as e:
            error_msg = f"è¯»å–å¤±è´¥: {e}"
            failed_files.append((csv_file.name, error_msg))
            print(f"âŒ {csv_file.name}: {error_msg}")
    
    # æŒ‰aliasæ’åº
    all_compounds.sort(key=lambda x: x['alias_or_code'])
    
    # å†™å…¥åˆå¹¶åçš„CSVæ–‡ä»¶
    try:
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            if all_compounds:
                fieldnames = ['databank', 'alias_or_code', 'registered_name', 'source_table']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(all_compounds)
        
        print(f"\nâœ… åˆå¹¶å®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   - æˆåŠŸæ–‡ä»¶: {processed_files}/{len(csv_files)} ä¸ª")
        print(f"   - æ€»åŒ–åˆç‰©: {total_compounds:,} ä¸ª")
        print(f"   - å»é‡å: {len(all_compounds):,} ä¸ª")
        print(f"   - å»é‡ç‡: {((total_compounds - len(all_compounds))/total_compounds*100):.1f}%" if total_compounds > 0 else "   - å»é‡ç‡: 0%")
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {output_file.stat().st_size:,} å­—èŠ‚")
        
        # æ˜¾ç¤ºå¤±è´¥æ–‡ä»¶
        if failed_files:
            print(f"\nâŒ å¤±è´¥æ–‡ä»¶:")
            for filename, error in failed_files:
                print(f"   {filename}: {error}")
        
        return len(all_compounds)
        
    except Exception as e:
        print(f"âŒ å†™å…¥è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
        return 0

def analyze_compounds(csv_file):
    """åˆ†æåŒ–åˆç‰©æ•°æ®"""
    
    if not csv_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
        return
    
    print(f"\nğŸ“Š åŒ–åˆç‰©æ•°æ®åˆ†æ:")
    print("=" * 50)
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            compounds = list(reader)
        
        print(f"ğŸ“ æ€»åŒ–åˆç‰©æ•°: {len(compounds):,}")
        
        # æŒ‰æ•°æ®åº“åˆ†ç±»ç»Ÿè®¡
        databank_stats = {}
        for compound in compounds:
            db = compound.get('databank', 'Unknown')
            databank_stats[db] = databank_stats.get(db, 0) + 1
        
        print(f"\nğŸ“‹ æŒ‰æ•°æ®åº“åˆ†ç±»:")
        for db, count in sorted(databank_stats.items()):
            print(f"   {db}: {count:,} ä¸ª")
        
        # æ˜¾ç¤ºå‰10ä¸ªåŒ–åˆç‰©æ ·ä¾‹
        print(f"\nğŸ” å‰10ä¸ªåŒ–åˆç‰©æ ·ä¾‹:")
        for i, compound in enumerate(compounds[:10], 1):
            alias = compound.get('alias_or_code', '')
            name = compound.get('registered_name', '')
            print(f"   {i:2d}. {alias} â†’ {name}")
        
        if len(compounds) > 10:
            print(f"   ... (è¿˜æœ‰ {len(compounds)-10:,} ä¸ª)")
            
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")

def main():
    # è¾“å…¥å’Œè¾“å‡ºè·¯å¾„
    input_dir = Path("example/data/parsed_csv")
    output_file = Path("example/data/final_compounds.csv")
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not input_dir.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        print("è¯·å…ˆè¿è¡Œ parse_tables.py æ¥è§£æè¡¨æ ¼")
        return
    
    # åˆå¹¶CSVæ–‡ä»¶
    compound_count = merge_csv_files(input_dir, output_file)
    
    # åˆ†æç»“æœ
    if compound_count > 0:
        analyze_compounds(output_file)
        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        print(f"ğŸ¯ æœ€ç»ˆç»“æœ: {compound_count:,} ä¸ªåŒ–åˆç‰© alias-name é…å¯¹")
        print(f"ğŸ“ ä¿å­˜åœ¨: {output_file}")
    else:
        print("âŒ åˆå¹¶å¤±è´¥ï¼")

if __name__ == "__main__":
    main() 